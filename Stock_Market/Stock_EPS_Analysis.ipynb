{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53cd55ab",
   "metadata": {},
   "source": [
    "# EPS Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a424bd",
   "metadata": {
    "code_folding": [
     27,
     39,
     66,
     120,
     138,
     162,
     191,
     233,
     287,
     322,
     347,
     397,
     433,
     489,
     514,
     555,
     617,
     652,
     678,
     709
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import alpha_vantage\n",
    "import csv\n",
    "import requests\n",
    "import warnings\n",
    "import math\n",
    "from itertools import cycle, islice\n",
    "import re\n",
    "import calendar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.stats as stats\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "warnings.simplefilter('ignore')\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "api_key = ('QFZF2CEU5FAI6YIW')\n",
    "sym = input(\"Input your stock ticker: \")\n",
    "\n",
    "class calls:\n",
    "    \n",
    "    def get_weekly_data():\n",
    "        \n",
    "        ts = TimeSeries(key= api_key, output_format = 'pandas')\n",
    "        df, meta_data = ts.get_weekly(symbol = sym.upper())\n",
    "\n",
    "        df.reset_index(inplace = True)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df.rename(columns = {'date': 'reportedDate'}, inplace = True)\n",
    "        df = df.sort_values(by = 'reportedDate')\n",
    "        \n",
    "        return(df)\n",
    "    \n",
    "    def merge_weekly_stock(frame, df, kicker): # merge stock earnings, with weekly data. Insert columns\n",
    "                \n",
    "        frame.sort_values(by = 'fiscalDateEnding', inplace = True)\n",
    "        \n",
    "        if kicker == 'TRUE':\n",
    "            frame.rename(columns = {'fiscalDateEnding': 'reportedDate'}, inplace = True)\n",
    "             #create Free Cash Flow \n",
    "            frame = frame.replace('None', 0)\n",
    "            frame['FreeCashFlow'] = frame['operatingCashflow'] - frame['capitalExpenditures']            \n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        new_df = pd.merge_asof(frame, df, on='reportedDate', direction='nearest')\n",
    "\n",
    "        # add in the most up to date stock price as the final column\n",
    "        end_stock_date = df['reportedDate'][0]\n",
    "        end_stock_val = df['4. close'][0]\n",
    "\n",
    "        # create the dict with to be the final row with proper date, & stock close. \n",
    "        keys = list(new_df.columns)\n",
    "        d = {key: None if key != '4. close' else end_stock_val for key in keys}\n",
    "        d['reportedDate']= end_stock_date\n",
    "        \n",
    "        new_df = new_df.append(d, ignore_index = True)\n",
    "        \n",
    "        return(new_df)\n",
    "    \n",
    "    def statement(statement):\n",
    "        \n",
    "        url = f'https://www.alphavantage.co/query?function={statement}&symbol={sym.upper()}&apikey={api_key}'\n",
    "    \n",
    "        if statement == 'CASH_FLOW':\n",
    "    \n",
    "            r = requests.get(url)\n",
    "\n",
    "            if r.status_code == 200:\n",
    "                try:\n",
    "                    cf_annual = pd.DataFrame(r.json()['annualReports'])\n",
    "                except:\n",
    "                    print('Annual Reports do not exist in cash flow call')\n",
    "                try:\n",
    "                    cf_quarterly = pd.DataFrame(r.json()['quarterlyReports'])\n",
    "                except:\n",
    "                    print('Quarterly Reports do not exist in cash flow call')\n",
    "                    \n",
    "\n",
    "                cf_quarterly[['paymentsForRepurchaseOfCommonStock', 'capitalExpenditures', 'operatingCashflow']] = cf_quarterly[['paymentsForRepurchaseOfCommonStock', 'capitalExpenditures', 'operatingCashflow']].replace('None', 0)\n",
    "                cf_annual[['paymentsForRepurchaseOfCommonStock', 'capitalExpenditures', 'operatingCashflow']] = cf_annual[['paymentsForRepurchaseOfCommonStock', 'capitalExpenditures', 'operatingCashflow']].replace('None', 0)\n",
    "                        \n",
    "                return(cf_annual, cf_quarterly)\n",
    "            \n",
    "        elif statement == 'EARNINGS':\n",
    "            \n",
    "                r = requests.get(url)\n",
    "                data = r.json()\n",
    "\n",
    "                if statement == 'EARNINGS':\n",
    "                    try:\n",
    "                        annual = pd.DataFrame(data['annualEarnings'])\n",
    "                        quarterly = pd.DataFrame(data['quarterlyEarnings'])\n",
    "                        annual['weekly'] = annual['fiscalDateEnding'].str[:7]\n",
    "                        quarterly['weekly'] = quarterly['reportedDate'].str[:7]\n",
    "                    except KeyError:\n",
    "                        print('Took many calls to the API within the time limit')\n",
    "                else:    \n",
    "                    annual = pd.DataFrame(data['annualReports'])\n",
    "                    quarterly = pd.DataFrame(data['quarterlyReports'])\n",
    "\n",
    "\n",
    "                # For rows with none replace with np.nan. Then replace 'reportedEPS' with 'estimatedEPS' if NaN. \n",
    "                quarterly = quarterly.replace('None', np.nan)\n",
    "                quarterly['estimatedEPS'].fillna(quarterly['reportedEPS'], inplace=True)\n",
    "                annual = annual.replace('None', np.nan)     \n",
    "                \n",
    "                quarterly['reportedEPS'] = quarterly['reportedEPS'].astype(float)\n",
    "                \n",
    "                quarterly['reportedEPS_diff'] = quarterly['reportedEPS'].diff()\n",
    "#                 annual['reportedEPS_diff'] = annual['reportedEPS'].diff()\n",
    "\n",
    "                return(annual, quarterly)  #get data via alpha vantage API\n",
    "         \n",
    "    def fix_dtypes(frame):\n",
    "                        \n",
    "        #change date_cols to datetime using regex\n",
    "        date_cols = list(frame.filter(regex=re.compile('date', re.IGNORECASE)).columns)\n",
    "        \n",
    "        \n",
    "        for i in date_cols:\n",
    "            frame[i] = pd.to_datetime(frame[i])\n",
    "        \n",
    "        #get remaining columns try to change to float, if error occurs then assume a string\n",
    "        other_cols = list(set(frame.columns) - set(date_cols))\n",
    "\n",
    "        for i in other_cols:\n",
    "            try:\n",
    "                frame[i] = frame[i].astype(float)\n",
    "            except ValueError:\n",
    "                frame[i] = frame[i].astype(str) # fix data types from the API call\n",
    "    \n",
    "    def scrape_splits():  # webscrape historical stock splits from said stock. \n",
    "        session = requests.Session()\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',}\n",
    "        url = 'https://www.stocksplithistory.com/?symbol={}'.format(sym.upper())\n",
    "        response = session.get(url, headers= headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', {'class': 'split-history-table'})\n",
    "        td_tags = soup.find_all('td', {'align': 'center', 'style': 'padding: 4px; border-bottom: 1px solid #CCCCCC'})\n",
    "\n",
    "\n",
    "        date_list = []\n",
    "        split_list = []\n",
    "\n",
    "        for i in range(0, len(td_tags), 2):\n",
    "            date = td_tags[i].text.strip()\n",
    "            split = td_tags[i+1].text.strip()\n",
    "            date_list.append(date)\n",
    "            split_list.append(split)\n",
    "\n",
    "        splits = pd.DataFrame({'Date': date_list, 'Split': split_list})\n",
    "        splits['Date'] = pd.to_datetime(splits['Date'])\n",
    "        splits_filt = splits.loc[splits['Date'] > '01/01/2000']\n",
    "        return(splits_filt)\n",
    "    \n",
    "    def normalize_stock_splits(df, scrape): #normalize the dataframe. \n",
    "\n",
    "        i = 0\n",
    "        while i < len(scrape):   \n",
    "\n",
    "            split_string = list(scrape['Split'].values)[i]\n",
    "            split_list = split_string.split(\"for\")\n",
    "            split_ratio = int(split_list[0].strip())\n",
    "\n",
    "            split_date = scrape['Date'].values[i]\n",
    "            split_date = pd.to_datetime(split_date)\n",
    "\n",
    "            #filter for current week up to split & everything prior. \n",
    "            mask = ((df['reportedDate'].dt.year < split_date.year) | \n",
    "                ((df['reportedDate'].dt.year == split_date.year) & (df['reportedDate'].dt.week < split_date.week)))\n",
    "            split_df = df.loc[mask]\n",
    "\n",
    "\n",
    "            split_df['1. open'] = split_df['1. open'] / split_ratio\n",
    "            split_df['2. high'] = split_df['2. high'] / split_ratio\n",
    "            split_df['3. low'] = split_df['3. low'] / split_ratio\n",
    "            split_df['4. close'] = split_df['4. close'] / split_ratio\n",
    "\n",
    "\n",
    "            df.update(split_df)\n",
    "            i += 1\n",
    "        \n",
    "        return(df)\n",
    "            \n",
    "    def plot_EPS_stock(df_merged):\n",
    "        df_merged = df_merged.loc[df_merged['reportedDate'].dt.year >= 1999]\n",
    "        \n",
    "        fig, ax1 = plt.subplots(figsize=(20, 10))\n",
    "        ax2 = ax1.twinx()\n",
    "\n",
    "        # plot the first line with the left y-axis\n",
    "        sns.lineplot(x='reportedDate', y='reportedEPS', data=df_merged, ax=ax1, color='orange', label='reportedEPS')\n",
    "\n",
    "        # plot the second line with the left y-axis\n",
    "        sns.lineplot(x='reportedDate', y='estimatedEPS', data=df_merged, ax=ax1, color='red', label='estimatedEPS')\n",
    "\n",
    "        # plot the third with the right y-axis\n",
    "        sns.lineplot(x='reportedDate', y='4. close', data=df_merged, color='green', label='Stock Price')\n",
    "\n",
    "        ax1.set_xlabel('')\n",
    "        ax1.set_ylabel('Earnings Per Share', fontsize=25)\n",
    "        ax1.tick_params(axis='both', which='major', labelsize=20)\n",
    "        ax2.set_ylabel('Stock Price', fontsize=25)\n",
    "        ax2.tick_params(axis='y', which='major', labelsize=20) \n",
    "        ax1.set_title('EPS & Stock Price', fontsize=25)\n",
    "\n",
    "        # adjust the position of the legends\n",
    "        legend1 = ax1.legend(loc='upper left', fontsize='x-large')\n",
    "        legend2 = ax2.legend(loc='upper right', fontsize='x-large', bbox_to_anchor=(1.2, 1))\n",
    "\n",
    "        # set zorder to bring the legends to the front\n",
    "        legend1.set_zorder(100)\n",
    "        legend2.set_zorder(100)\n",
    "\n",
    "        last_date = df_merged['reportedDate'].iloc[-3]\n",
    "        ax1.axvline(x=last_date, linestyle='dotted', color='black')\n",
    "\n",
    "        ax1.invert_yaxis()\n",
    "\n",
    "        # show the grid lines behind the legends\n",
    "        ax1.grid(True, linestyle='dotted', zorder=0)\n",
    "        ax2.grid(True, linestyle='dotted', zorder=0)\n",
    "        ax1.set_xlim(df_merged['reportedDate'].iloc[0])\n",
    "\n",
    "        plt.show()  # EPS vs Stock Plot #plot EPS, vs stock price weekly \n",
    "    \n",
    "    def get_next_numbers():  #scraping future earnings\n",
    "    \n",
    "        session = requests.Session()\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',}\n",
    "\n",
    "        url = 'https://www.zacks.com/stock/quote/{}/detailed-earning-estimates'.format(sym.upper())\n",
    "        response = session.get(url, headers = headers)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        tags = soup.find_all('a', href='/stock/chart/{}/price-consensus-eps-surprise-chart'.format(sym.upper()))\n",
    "\n",
    "        number_values = []\n",
    "        for tag in tags:\n",
    "            text = tag.text\n",
    "            number_values.append(text)\n",
    "\n",
    "        t = soup.find_all('th', {'class': ''})\n",
    "\n",
    "        tag_list = []\n",
    "        for tags in t:\n",
    "            tag_list.append(tags.text)\n",
    "\n",
    "        t = pd.DataFrame(tag_list, columns = ['Tags'])\n",
    "        t = pd.DataFrame(t['Tags'].drop_duplicates())\n",
    "        t = t[t['Tags'].str.contains('Qtr|Year')]\n",
    "\n",
    "        frame = {'Revenue': number_values[1:5],\n",
    "                'EPS': number_values[6:10]}\n",
    "\n",
    "        index = list(t['Tags'][0:4].values)\n",
    "        scrape = pd.DataFrame(frame, index=index)\n",
    "        #---------------------------------------\n",
    "\n",
    "        tds = soup.find_all('td', {'class': 'alpha'})\n",
    "\n",
    "        data = []       \n",
    "        for td in tds:\n",
    "            row = {}\n",
    "            if td.text == 'Current' or td.text == '7 Days Ago' or td.text == '30 Days Ago' or td.text == '60 Days Ago' or td.text == '90 Days Ago':\n",
    "                row['Period'] = td.text\n",
    "                row['Value1'] = td.find_next_siblings('td')[0].text\n",
    "                row['Value2'] = td.find_next_siblings('td')[1].text\n",
    "                row['Value3'] = td.find_next_siblings('td')[2].text\n",
    "                row['Value4'] = td.find_next_siblings('td')[3].text\n",
    "                data.append(row)\n",
    "\n",
    "        consensus = pd.DataFrame(data)\n",
    "        consensus.set_index('Period', inplace = True)\n",
    "        col_dict = dict(zip(list(consensus.columns), index))\n",
    "        consensus = consensus.rename(columns = col_dict)\n",
    "\n",
    "        return(scrape, consensus)\n",
    "    \n",
    "    def insert_proj_EPS(current_or_next, frame, proj): #insert projected EPS\n",
    "    \n",
    "        #get the last record of earnings quarterly and offset by 3 months\n",
    "        fiscal_val = frame.iloc[len(frame) -1]['fiscalDateEnding']\n",
    "        reported_val = frame.iloc[len(frame) -1]['reportedDate']\n",
    "        offset = pd.DateOffset(months = 3)\n",
    "\n",
    "        fiscal_date_end = fiscal_val+offset\n",
    "        reported_date_end = reported_val + offset\n",
    "\n",
    "        if current_or_next == 'current':\n",
    "            qtr = proj['EPS'][0]\n",
    "        elif current_or_next == 'next':\n",
    "            qtr = proj['EPS'][1]\n",
    "        else:\n",
    "            print('Error with naming convention')\n",
    "\n",
    "\n",
    "        first_row = pd.DataFrame({\n",
    "            'fiscalDateEnding': [fiscal_date_end],\n",
    "            'reportedDate': [reported_date_end],\n",
    "            'reportedEPS': [None],\n",
    "            'estimatedEPS': [qtr],\n",
    "            'surprise': [0],\n",
    "            'surprisePercentage': [0],\n",
    "            'weekly': ['2023']\n",
    "        })\n",
    "\n",
    "        if current_or_next == 'current':\n",
    "            frame.loc[-1] = first_row.iloc[0]\n",
    "        elif current_or_next == 'next':\n",
    "            frame.loc[-2] = first_row.iloc[0]\n",
    "        else:\n",
    "            print('Error with row update')\n",
    "        \n",
    "    def EPS_frame():\n",
    "\n",
    "        df_merged.set_index('reportedDate', inplace=True)\n",
    "        EPS_frame = df_merged.loc[:, ['reportedEPS', 'estimatedEPS']]\n",
    "\n",
    "        # get the projections for next quarter to assume the empty spaces. \n",
    "        EPS_frame['reportedEPS'] = EPS_frame['reportedEPS'].fillna(EPS_frame['estimatedEPS'])\n",
    "        EPS_frame = EPS_frame[['reportedEPS']]\n",
    "        EPS_frame['reportedEPS'] = EPS_frame['reportedEPS'].astype(float)\n",
    "\n",
    "        EPS_frame['percentage_change'] = EPS_frame.pct_change(periods=4)\n",
    "\n",
    "        # Identify the indices where the reportedEPS changed from negative to positive\n",
    "        positive_indices = EPS_frame.loc[(EPS_frame['reportedEPS'] > 0) & (EPS_frame['reportedEPS'].shift(4) < 0)].index\n",
    "        # Update the percentage_change column to be positive for the identified indices\n",
    "        EPS_frame.loc[positive_indices, 'percentage_change'] = EPS_frame.loc[positive_indices, 'percentage_change'].abs()\n",
    "\n",
    "        EPS_frame['percentage_change'] = EPS_frame['percentage_change'] * 100\n",
    "        EPS_frame['percentage_change'] = EPS_frame['percentage_change'].round(2) \n",
    "        EPS_frame_ = EPS_frame\n",
    "        EPS_frame = EPS_frame[::-1]\n",
    "        EPS_frame = EPS_frame.transpose()\n",
    "        display(EPS_frame.head(50))\n",
    "        return(EPS_frame_)\n",
    "    \n",
    "    def average_best_EPS(EPS_frame):\n",
    "        \n",
    "        #create quarter groupings based on the amount of instances in year one. Then replicate the pattern. \n",
    "        months = pd.DataFrame(EPS_frame.index.month.value_counts()).sort_index()\n",
    "    \n",
    "        while len(months) > 4:\n",
    "            min_reported_date = months['reportedDate'].min()\n",
    "            months = months[months['reportedDate'] != min_reported_date]\n",
    "\n",
    "        months = months.reset_index()\n",
    "        months.rename(columns = {'index': 'month'}, inplace = True)\n",
    "\n",
    "        months['month'] = months.month.apply(lambda x: calendar.month_name[x])\n",
    "\n",
    "        year_one = EPS_frame.index[0].year\n",
    "        year_one = EPS_frame.loc[EPS_frame.index.year == year_one]\n",
    "\n",
    "        if len(year_one) == 4:\n",
    "            pattern = [months['month'][0], months['month'][1], months['month'][2], months['month'][3]]\n",
    "        elif len(year_one) == 3:\n",
    "            pattern = [months['month'][1], months['month'][2], months['month'][3], months['month'][0]]\n",
    "        elif len(year_one) == 2:\n",
    "            pattern = [months['month'][2], months['month'][3], months['month'][0], months['month'][1]]\n",
    "        elif len(year_one) == 2:\n",
    "            pattern = [months['month'][3], months['month'][0], months['month'][1], months['month'][2]]\n",
    "\n",
    "\n",
    "        repeating_pattern = list(islice(cycle(pattern), len(EPS_frame)))\n",
    "\n",
    "        # Assign the pattern to the column\n",
    "        EPS_frame['quarter_groupings'] = repeating_pattern\n",
    "                \n",
    "        # Filter the data based on quarter_groupings\n",
    "        EPS_frame = EPS_frame.reset_index()\n",
    "\n",
    "        #Create a line plot for each quarter_grouping\n",
    "        plt.figure(figsize=(18, 10))\n",
    "        for group, group_df in EPS_frame.groupby('quarter_groupings'):\n",
    "            plt.plot(group_df['reportedDate'], group_df['reportedEPS'], marker='o', linestyle='-', label=f\"{group}\")\n",
    "\n",
    "        plt.title('reportedEPS by Quarter Groupings', fontsize = 25)\n",
    "        plt.xlabel('Reported Date', fontsize = 25)\n",
    "        \n",
    "        plt.ylabel('reportedEPS', fontsize = 20)\n",
    "        plt.legend()\n",
    "        plt.xticks(fontsize=20)\n",
    "        plt.yticks(fontsize=20)\n",
    "        plt.grid(True)\n",
    "        plt.show()   #reportedEPS by Quarter Groupings\n",
    "\n",
    "    def plot_EPS_hbar(df):\n",
    "\n",
    "        # Set the figure size and create subplots\n",
    "        fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "        # Plot the horizontal bars with customized colors\n",
    "        bars = ax.barh(df.index, df['reportedEPS'], color='black', edgecolor='black', linewidth=0.8)\n",
    "\n",
    "        # Set the labels and title\n",
    "        ax.set_xlabel('Reported EPS', fontsize=25)\n",
    "        ax.tick_params(axis='x', which='major', labelsize=20) \n",
    "        ax.set_ylabel('Reported Date', fontsize=20)\n",
    "        ax.tick_params(axis='y', which='major', labelsize=20)\n",
    "        ax.set_title('Reported EPS by Period', fontsize=25 )\n",
    "\n",
    "        # Add data labels to the bars\n",
    "        for bar in bars:\n",
    "            value = bar.get_width()\n",
    "            x = value\n",
    "            if value < 0:\n",
    "                x = 0\n",
    "                ax.text(value, bar.get_y() + bar.get_height() / 2, f'{value:.2f}', va='center', ha='right', color='black', fontsize = 12)\n",
    "            else:\n",
    "                ax.text(value, bar.get_y() + bar.get_height() / 2, f'{value:.2f}', va='center', ha='left', color='black', fontsize = 12)\n",
    "\n",
    "        # Customize the plot background color\n",
    "        ax.set_facecolor('lightgray')\n",
    "\n",
    "        # Customize the ticks and grid lines\n",
    "        ax.tick_params(axis='both', colors='black')\n",
    "        ax.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "        # Display the plot\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def correlation_average():\n",
    "        \n",
    "        # first create the out frame which groups the months by EPS diff. \n",
    "        sub = df_merged[['fiscalDateEnding', '4. close', 'reportedEPS', 'reportedEPS_diff']]\n",
    "        sub['reportedEPS'] = sub['reportedEPS'].astype(float)\n",
    "\n",
    "        out = sub.groupby(sub['fiscalDateEnding'].dt.month)[['reportedEPS_diff']].mean()\n",
    "        out.reset_index(inplace =True)\n",
    "        \n",
    "\n",
    "        years = list(df_merged['fiscalDateEnding'].dt.year.unique())\n",
    "\n",
    "        for i in years:\n",
    "                small = df_merged.loc[df_merged['fiscalDateEnding'].dt.year == i]\n",
    "                small['reportedEPS_diff'] = small['reportedEPS_diff'].astype(float)\n",
    "                try:\n",
    "                    out[str(i)] = small['reportedEPS_diff'].values\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        corr_list = []\n",
    "        year_list = []\n",
    "\n",
    "        for year in years:\n",
    "                try:\n",
    "\n",
    "                    correlation, p_value = stats.pearsonr(out['reportedEPS_diff'], out[str(year)])\n",
    "                    corr_list.append(correlation)\n",
    "                    year_list.append(year)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                except KeyError:\n",
    "                    pass\n",
    "\n",
    "        corr_frame = pd.DataFrame(corr_list, index=year_list, columns=['EPS correlation YoY'])\n",
    "\n",
    "        a = [x for x in corr_list if not math.isnan(x)]\n",
    "\n",
    "        # test correlation for most recent 60% or results\n",
    "        portion = round(.60 * len(a))\n",
    "        a_portion = [a[int(-portion):]]\n",
    "        a_portion = [item for sublist in a_portion for item in sublist]\n",
    "\n",
    "        a = (sum(a) / len(a))\n",
    "        a_portion = (sum(a_portion) / len(a_portion))\n",
    "\n",
    "        text = (f'\\nAverage correlation value for all years {round(a, 2)}')\n",
    "        formatted_text = \"\\033[1;4m{}\\033[0m\".format(text)    \n",
    "        print(f\"{formatted_text}\")\n",
    "\n",
    "        text = (f'Average correlation value of last {str(int(portion))} years: {round(a_portion, 2)}')\n",
    "        formatted_text = \"\\033[1;4m{}\\033[0m\".format(text)    \n",
    "        print(f\"{formatted_text}\")\n",
    "\n",
    "        return(corr_frame) #correlation average chart\n",
    "    \n",
    "    def show_corrs():\n",
    "        # Extract correlation values (excluding None/NaN values)\n",
    "        correlations = [value for value in corr_frame['EPS correlation YoY'].values if value is not None]\n",
    "\n",
    "        # Create figure and axes\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "        # Plot histogram on the first subplot (ax1)\n",
    "        bins = [-1, -0.7, -0.45, 0, 0.45, 0.7, 1]\n",
    "        ax1.hist(correlations, bins=bins, edgecolor='black', orientation='horizontal')\n",
    "        ax1.set_xlabel('Frequency', fontsize = 20)\n",
    "        ax1.set_ylabel('EPS Correlation YoY Buckets', fontsize = 20)\n",
    "        ax1.set_title('Histogram of EPS Correlation YoY', fontsize = 25)\n",
    "                     \n",
    "\n",
    "        # Display the DataFrame on the second subplot (ax2)\n",
    "        ax2.axis('off')  # Hide the axes\n",
    "        ax2.text(0.5, 0.5, corr_frame.to_string(), va='center', ha='center', fontsize=14)  # Display DataFrame as text\n",
    "\n",
    "        # Adjust spacing between subplots\n",
    "        fig.tight_layout()\n",
    "\n",
    "        # Show the figure\n",
    "        plt.show()\n",
    "        \n",
    "    def EPS_cycle():\n",
    "\n",
    "        sub = df_merged[['fiscalDateEnding', '4. close', 'reportedEPS', 'reportedEPS_diff']]\n",
    "        sub['reportedEPS'] = sub['reportedEPS'].astype(float)\n",
    "\n",
    "        # Set up output\n",
    "        output = sub.groupby(sub['fiscalDateEnding'].dt.month)[['reportedEPS_diff']].mean()\n",
    "        output = output.sort_index()\n",
    "        output.index = output.index.map(lambda x: calendar.month_name[x])\n",
    "\n",
    "        sub = sub.reset_index()\n",
    "        sub = sub[['fiscalDateEnding', 'reportedDate']]\n",
    "        sub['month_combination'] = sub.apply(lambda row: f\"{calendar.month_name[row['fiscalDateEnding'].month]}, {calendar.month_name[row['reportedDate'].month]}\", axis=1)\n",
    "\n",
    "        month_combo = pd.DataFrame(sub['month_combination'].value_counts().sort_values())\n",
    "\n",
    "        def minimize(months):\n",
    "            while len(months) > 4:\n",
    "                min_reported_date = months['month_combination'].min()\n",
    "                months = months[months['month_combination'] != min_reported_date]\n",
    "\n",
    "            months = months.reset_index()\n",
    "            months.rename(columns = {'index': 'month'}, inplace = True)\n",
    "\n",
    "        #     Split the two columns here. \n",
    "            months[['fiscalDateEnding', 'reportedDate']] = months['month'].str.split(', ', expand=True)\n",
    "            month_dict = dict(zip(months['fiscalDateEnding'], months['reportedDate']))\n",
    "\n",
    "            return(month_dict)\n",
    "\n",
    "        month_dict = minimize(month_combo)\n",
    "        output.index = output.index.map(month_dict)\n",
    "        output.index.name = 'Reported Date'\n",
    "        output = output.reset_index()\n",
    "        \n",
    "        ax = sns.lineplot(x='Reported Date', y='reportedEPS_diff', data=output, marker='o')\n",
    "        ax.set_xlabel('Month Reported', fontsize=20)\n",
    "        ax.set_ylabel('reportedEPS_diff', fontsize=20)\n",
    "        ax.set_title('Avg EPS difference QoQ (All Years)', fontsize = 25)\n",
    "        plt.show()\n",
    "    \n",
    "    def month_agg_graph():\n",
    "\n",
    "        # get the earliest day in the month, and get the last day in that month. Find the percent difference of 4. close\n",
    "        df = df_2[['reportedDate', '4. close']]\n",
    "\n",
    "        df['reportedDate'] = pd.to_datetime(df['reportedDate'])\n",
    "        df.set_index('reportedDate', inplace=True)\n",
    "\n",
    "        # Resample to monthly frequency and calculate percentage change\n",
    "        monthly_change = df['4. close'].resample('M').agg(['first', 'last'])\n",
    "\n",
    "\n",
    "        monthly_change['percentage_change'] = (monthly_change['last'] - monthly_change['first']) / monthly_change['first'] * 100\n",
    "        monthly_change['percentage_change'] = round(monthly_change['percentage_change'],2)\n",
    "\n",
    "        # Create subplots\n",
    "        fig, axes = plt.subplots(4, 3, figsize=(15, 20))\n",
    "\n",
    "        # Iterate over each month\n",
    "        for i, month in enumerate(range(1, 13)):\n",
    "            # Calculate the position of the subplot in the grid\n",
    "            row = i // 3\n",
    "            col = i % 3\n",
    "\n",
    "            # Filter data for the current month\n",
    "            monthly_data = monthly_change[monthly_change.index.month == month]\n",
    "\n",
    "            # Calculate the percentage of positive changes\n",
    "            positive_percentage = (monthly_data['percentage_change'] > 0).mean() * 100\n",
    "\n",
    "            # Plot horizontal bar in the corresponding subplot\n",
    "            ax = axes[row, col]  # Get the current subplot\n",
    "            monthly_data[['percentage_change']].plot.barh(ax=ax, legend=False)  # Turn off legend\n",
    "\n",
    "            # Set title and labels\n",
    "            ax.set_title(f'{monthly_data.index[0].strftime(\"%B\")}% Change({positive_percentage:.1f}% +)', fontsize = 20)\n",
    "            ax.set_xlabel('% Change')\n",
    "            ax.set_ylabel('Month')\n",
    "\n",
    "            # Set a common x-axis range for all subplots\n",
    "            ax.set_xlim([-50, 50])  # Adjust the range as per your data\n",
    "\n",
    "             # Customize y-axis tick labels\n",
    "            ax.set_yticks(range(len(monthly_data)))\n",
    "            ax.set_yticklabels(monthly_data.index.strftime('%Y-%m-%d').tolist()) \n",
    "\n",
    "            # Add percentage values as annotations\n",
    "            for i, value in enumerate(monthly_data['percentage_change']):\n",
    "                if value >= 0:\n",
    "                    xytext = (5, 0)\n",
    "                    ha = 'left'\n",
    "                else:\n",
    "                    xytext = (-5, 0)\n",
    "                    ha = 'right'\n",
    "                ax.annotate(f'{value:.2f}', xy=(value, i), xytext=xytext, textcoords='offset points', ha=ha, va='center')\n",
    "\n",
    "        # Adjust spacing between subplots and remove any empty subplots\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Show the figure\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_change(column):\n",
    "\n",
    "        frame = df_merged\n",
    "        frame['year'] = frame['fiscalDateEnding'].dt.year\n",
    "        years = list(frame['fiscalDateEnding'].dt.year.unique())\n",
    "\n",
    "        # Calculate the number of rows and columns needed based on the number of years\n",
    "        n_rows = (len(years) - 1) // 3 + 1\n",
    "        n_cols = min(len(years), 6)\n",
    "\n",
    "        fig, axs = plt.subplots(n_rows, n_cols, figsize=(15, 2*n_rows))\n",
    "\n",
    "        # Loop over the subplots and plot each year's data\n",
    "        for i, n in enumerate(years):\n",
    "            subset = frame.loc[frame['fiscalDateEnding'].dt.year == years[i]]\n",
    "\n",
    "            row = i // n_cols\n",
    "            col = i % n_cols\n",
    "\n",
    "            sns.lineplot(data=subset, x='reportedDate', y=column,  ax=axs[row, col])\n",
    "            #sns.scatterplot(data=subset, x='reportedDate', y=column, ax=axs[row, col], s=50, linewidth=1, edgecolor='black', zorder=3)\n",
    "            axs[row, col].set_title(years[i])\n",
    "            axs[row, col].set_xlabel(None)\n",
    "            axs[row, col].set_ylabel(None)\n",
    "            axs[row, col].set_xticklabels(axs[row, col].get_xticklabels(), rotation=45)\n",
    "\n",
    "        #     Remove any unused subplots\n",
    "        for i in range(len(years), n_rows * n_cols):\n",
    "            row = i // n_cols\n",
    "            col = i % n_cols\n",
    "            fig.delaxes(axs[row, col])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()  #Show subplot of YoY EPS\n",
    "        \n",
    "    def estimates(consensus, quarter_or_annual):  #linechart of consensus estimates EPS\n",
    "    \n",
    "        consensus[list(consensus.columns)] = consensus[list(consensus.columns)].astype(float)\n",
    "\n",
    "        if quarter_or_annual == 'quarter':\n",
    "            consensus = consensus.iloc[:, :2]\n",
    "        elif quarter_or_annual == 'annual':\n",
    "            consensus = consensus.iloc[:, 2:4]\n",
    "        else:\n",
    "            print('wrong input')\n",
    "\n",
    "        sns.set(style=\"darkgrid\")\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        ax = sns.lineplot(data=consensus,linewidth=3.0)\n",
    "\n",
    "        ax.invert_xaxis()\n",
    "\n",
    "        # Set the title and labels\n",
    "        plt.title(f'{quarter_or_annual.upper()} EPS Consensus Trends', fontsize = 25)\n",
    "        plt.xlabel('Date', fontsize = 25)\n",
    "        plt.ylabel('EPS', fontsize = 25)\n",
    "        plt.legend(fontsize='x-large', loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "        # Display the chart\n",
    "        plt.show()\n",
    "\n",
    "    def cash_flows():\n",
    "        \n",
    "        df_sub = df_merged_2[['reportedDate', 'operatingCashflow', 'cashflowFromInvestment', 'cashflowFromFinancing', 'FreeCashFlow']]\n",
    "        # Remove the last row with NaN values\n",
    "        df_sub = df_sub[:-1]\n",
    "        # Melt the dataframe to create a long-form dataframe\n",
    "        df_long = pd.melt(df_sub, id_vars=['reportedDate'], var_name='Cash Flow', value_name='Amount')\n",
    "        # Create the bar chart using matplotlib\n",
    "        fig, ax = plt.subplots(figsize=(24, 18))\n",
    "        df_long.pivot(index='reportedDate', columns='Cash Flow', values='Amount').plot(kind='bar', ax=ax)\n",
    "        # Add axis labels and a title\n",
    "        plt.xlabel('')\n",
    "        plt.ylabel(\"Amount\", fontsize=30)\n",
    "        plt.title(\"Cash Flows Over Time\", fontsize=35)\n",
    "        ax = plt.gca()\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), fontsize=20)\n",
    "        ax.legend(fontsize='x-large')\n",
    "\n",
    "        ax2 = ax.twinx()\n",
    "        df_merged_2['4. close'].plot(ax=ax2, color='gray', alpha=0.5, label='Stock Price')  # Include label for legend\n",
    "        ax2.set_ylabel(\"Stock Price\", fontsize=25)\n",
    "\n",
    "        # Combine the legends from both axes\n",
    "        handles1, labels1 = ax.get_legend_handles_labels()\n",
    "        handles2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax.legend(handles1 + handles2, labels1 + labels2, fontsize='x-large')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------           \n",
    "    \n",
    "def process_data(statement):   \n",
    "    # load the initial data into the frames\n",
    "    \n",
    "    if statement == 'CASH_FLOW':\n",
    "    \n",
    "        df = calls.get_weekly_data()\n",
    "        cf_annual, cf_quarterly = calls.statement(statement)\n",
    "\n",
    "        # fix data types in place\n",
    "        calls.fix_dtypes(cf_annual)\n",
    "        calls.fix_dtypes(cf_quarterly)  \n",
    "\n",
    "        # scrape and normalize stock splits\n",
    "        scrape = calls.scrape_splits()\n",
    "        df = calls.normalize_stock_splits(df, scrape)\n",
    "        df_merge = calls.merge_weekly_stock(cf_quarterly, df, 'TRUE')\n",
    "        \n",
    "        return(df_merge, df)\n",
    "        \n",
    "    elif statement == 'EARNINGS':\n",
    "        \n",
    "        df = calls.get_weekly_data()\n",
    "        earnings_annual, earnings_quarterly = calls.statement(statement)\n",
    "\n",
    "        calls.fix_dtypes(earnings_annual)\n",
    "        calls.fix_dtypes(earnings_quarterly)\n",
    "\n",
    "        scrape = calls.scrape_splits()\n",
    "        df = calls.normalize_stock_splits(df, scrape)\n",
    "        df_merged = calls.merge_weekly_stock(earnings_quarterly, df, 'FALSE')\n",
    "        \n",
    "        #drop last row with close data\n",
    "        df_merged = df_merged.drop(len(df_merged) - 1)\n",
    "        df_merged['reportedEPS_diff'] = df_merged['reportedEPS'].diff()\n",
    "        \n",
    "        proj, consensus = calls.get_next_numbers()\n",
    "        \n",
    "        calls.insert_proj_EPS('current', df_merged, proj)\n",
    "        calls.insert_proj_EPS('next', df_merged, proj)   \n",
    "        \n",
    "        df_merged.at[-1, '4. close'] = df.at[0, '4. close']\n",
    "        \n",
    "        return(df_merged, df, proj, consensus)\n",
    "    \n",
    "    else:\n",
    "        print(\"issue\")\n",
    "    \n",
    "    \n",
    "df_merged, df_2, proj, consensus = process_data('EARNINGS')\n",
    "df_merged_2, df_2_ = process_data('CASH_FLOW')\n",
    "    \n",
    "text = f\"\\n\\n\\nLast reported EPS: {df_merged.iloc[-3]['reportedEPS']} on {str(df_merged.iloc[-3]['reportedDate'])[:10]}\"\n",
    "formatted_text = \"\\033[1;4m{}\\033[0m\".format(text)    \n",
    "print(f\"{formatted_text}\")\n",
    "\n",
    "display(proj)\n",
    "calls.plot_EPS_stock(df_merged)\n",
    "EPS_frame = calls.EPS_frame()\n",
    "calls.plot_EPS_hbar(EPS_frame)\n",
    "print('\\n\\n\\n\\n ')\n",
    "calls.average_best_EPS(EPS_frame)\n",
    "\n",
    "print('\\n\\n\\n\\n ')\n",
    "text = ('Earnings Cycle Correlation, takes the difference in EPS from Quarter to Quarter and compares YoY correlation')\n",
    "formatted_text = \"\\033[1;4m{}\\033[0m\".format(text)    \n",
    "print(f\"{formatted_text}\")\n",
    "corr_frame = calls.correlation_average()\n",
    "calls.show_corrs()\n",
    "\n",
    "\n",
    "# # Create the bar plot\n",
    "calls.EPS_cycle()\n",
    "\n",
    "text = f\"\\n\\n\\n\\nPercent of Positive Returns YoY Aggregated by Month\"\n",
    "formatted_text = \"\\033[1;4m{}\\033[0m\".format(text)    \n",
    "print(f\"{formatted_text}\")\n",
    "\n",
    "calls.month_agg_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36bacc0",
   "metadata": {},
   "source": [
    "# Analyst EPS Forecasts, Cash Flow Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c15e23b",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "calls.estimates(consensus, 'quarter')\n",
    "calls.estimates(consensus, 'annual')\n",
    "text = ('\\n\\n\\nAnalyst EPS Consensus Trends')\n",
    "formatted_text = \"\\033[1;4m{}\\033[0m\".format(text)    \n",
    "print(f\"{formatted_text}\")\n",
    "display(consensus)\n",
    "\n",
    "calls.cash_flows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71bf746",
   "metadata": {},
   "source": [
    "# Cash Flow From Invesment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44def82",
   "metadata": {},
   "source": [
    "Cash flow from investments refers to the amount of cash inflow or outflow generated from a company's investments in assets, such as property, equipment, securities, or other investments. Here are some examples of cash flow from investment:\n",
    "\n",
    "Purchase of property: When a company purchases a property, the cash outflow from the investment will be recorded as a negative cash flow from investment.\n",
    "\n",
    "Sale of property: When a company sells a property, the cash inflow from the sale will be recorded as a positive cash flow from investment.\n",
    "\n",
    "Purchase of equipment: When a company purchases new equipment, the cash outflow from the investment will be recorded as a negative cash flow from investment.\n",
    "\n",
    "Sale of equipment: When a company sells equipment, the cash inflow from the sale will be recorded as a positive cash flow from investment.\n",
    "\n",
    "Purchase of securities: When a company purchases securities, such as stocks or bonds, the cash outflow from the investment will be recorded as a negative cash flow from investment.\n",
    "\n",
    "Sale of securities: When a company sells securities, the cash inflow from the sale will be recorded as a positive cash flow from investment.\n",
    "\n",
    "Dividend income: When a company receives dividends from its investments, the cash inflow from the dividend income will be recorded as a positive cash flow from investment.\n",
    "\n",
    "Interest income: When a company receives interest on its investments, the cash inflow from the interest income will be recorded as a positive cash flow from investment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bafa1c",
   "metadata": {},
   "source": [
    "# Cash Flow From Financing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a44f2",
   "metadata": {},
   "source": [
    "Cash flow from financing refers to the inflow and outflow of cash resulting from a company's financing activities, such as borrowing money, issuing stock, or paying dividends to shareholders. These activities affect the company's capital structure and the overall amount of debt and equity that the company holds.\n",
    "\n",
    "Here are some examples of cash flow from financing:\n",
    "\n",
    "Issuing new stock: When a company issues new shares of stock, the cash inflow from the sale of those shares is recorded as a positive cash flow from financing.\n",
    "\n",
    "Repurchasing stock: When a company buys back its own stock, the cash outflow from the repurchase is recorded as a negative cash flow from financing.\n",
    "\n",
    "Issuing debt: When a company borrows money through issuing bonds or taking out loans, the cash inflow from the debt issuance is recorded as a positive cash flow from financing.\n",
    "\n",
    "Repaying debt: When a company pays off its debt, the cash outflow from the repayment is recorded as a negative cash flow from financing.\n",
    "\n",
    "Paying dividends: When a company pays dividends to its shareholders, the cash outflow from the payment is recorded as a negative cash flow from financing.\n",
    "\n",
    "The net result of cash flow from financing activities can indicate whether a company is funding its operations through debt or equity, and whether it is generating enough cash to pay its obligations or requires additional financing to continue operating. Investors and analysts use this information to evaluate a company's financial health and investment potential.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c63805",
   "metadata": {},
   "source": [
    "# Cash Flow From Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb513477",
   "metadata": {},
   "source": [
    "\n",
    "Cash flow from operations represents the cash generated or consumed by a company's core business activities. It includes cash inflows and outflows directly related to day-to-day operations. Here are some examples:\n",
    "\n",
    "Cash inflows from operations:\n",
    "\n",
    "Cash received from customer payments for products or services.\n",
    "Cash received from the collection of accounts receivable.\n",
    "Cash received from the sale of inventory.\n",
    "Cash received from interest or dividends earned on investments.\n",
    "Cash outflows from operations:\n",
    "\n",
    "Cash payments to suppliers for raw materials or inventory.\n",
    "Cash payments to employees as wages or salaries.\n",
    "Cash payments for operating expenses such as rent, utilities, and insurance.\n",
    "Cash payments for taxes, both income taxes and sales taxes.\n",
    "Cash payments for interest on loans or credit lines."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
